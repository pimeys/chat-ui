# Nexus configuration for Docker Compose environment

[server]
listen_address = "0.0.0.0:8000"

[server.health]
enabled = true
path = "/health"

# Enable client identification for metrics tracking
[server.client_identification]
enabled = true
client_id.http_header = "x-client-id"
group_id.http_header = "x-client-group"

[server.client_identification.validation]
group_values = ["free", "pro", "max"]

# CORS configuration - allow all origins for development
[server.cors]
allow_credentials = false
allow_origins = "*"
allow_methods = ["GET", "POST", "OPTIONS"]
allow_headers = "*"

# Telemetry configuration for OpenTelemetry metrics
[telemetry]
service_name = "nexus-docker"

[telemetry.resource_attributes]
environment = "docker"
instance = "nexus-1"

[telemetry.exporters.otlp]
enabled = true
endpoint = "http://otel-collector:4317"
protocol = "grpc"
timeout = "60s"

[telemetry.exporters.otlp.batch_export]
scheduled_delay = "5s"
max_queue_size = 2048
max_export_batch_size = 512

# MCP Configuration
[mcp]
enabled = true
path = "/mcp"

# GitHub MCP Server - Search and interact with GitHub repositories
# https://github.com/github/github-mcp-server
# Comment out these lines if you don't have a GitHub PAT token
[mcp.servers.github]
url = "https://api.githubcopilot.com/mcp/"

[mcp.servers.github.auth]
token = "{{ env.GITHUB_TOKEN }}"

# LLM Configuration
[llm]
enabled = true
path = "/llm"

# OpenAI Provider (if API key is provided)
[llm.providers.openai]
type = "openai"
api_key = "{{ env.OPENAI_API_KEY }}"

[llm.providers.openai.models."gpt-4.1"]
rename = "gpt-4.1-2025-04-14"

# Anthropic Provider (if API key is provided)
[llm.providers.anthropic]
type = "anthropic"
api_key = "{{ env.ANTHROPIC_API_KEY }}"

[llm.providers.anthropic.models."claude-3-5-sonnet-latest"]
[llm.providers.anthropic.models."claude-3-5-haiku-latest"]
[llm.providers.anthropic.models."claude-3-opus-latest"]

# Google Provider (if API key is provided)
[llm.providers.google]
type = "google"
api_key = "{{ env.GOOGLE_API_KEY }}"

[llm.providers.google.models."gemini-2.5-flash"]
[llm.providers.google.models."gemini-2.5-pro"]
